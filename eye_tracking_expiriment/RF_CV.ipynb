{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "# used chatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features and labels\n",
    "features_array = np.load('x_data.npy', allow_pickle=True)\n",
    "labels_array = np.load('y_label.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [\n",
    " 'font_size', 'right_gaze_point_in_user_x', 'left_gaze_point_in_user_z', \n",
    "'left_gaze_point_on_display_area_y', 'right_gaze_point_on_display_area_x', \n",
    "'right_gaze_point_in_user_z', 'right_gaze_point_in_user_y', \n",
    " 'left_gaze_point_in_user_x', 'right_pupil_diameter', \n",
    " 'left_gaze_origin_in_trackbox_z', 'right_gaze_origin_in_trackbox_y', \n",
    " 'left_gaze_origin_in_trackbox_x', 'right_gaze_origin_in_user_z', \n",
    " 'left_gaze_origin_in_user_x', 'left_gaze_origin_in_user_y', \n",
    " 'left_gaze_origin_validity', 'right_gaze_origin_validity', \n",
    " 'device_time_stamp', 'left_gaze_point_validity', \n",
    " 'right_gaze_point_validity', 'left_pupil_validity', 'right_pupil_validity'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataframes = []\n",
    "for df in features_array:\n",
    "  #Drop the columns if they exist, ignore errors if some columns don't exist\n",
    "  new_df = df.drop(columns=columns_to_remove, errors='ignore')\n",
    "  processed_dataframes.append(new_df)\n",
    "\n",
    "features_array = np.array(processed_dataframes, dtype=object)           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "lengths = [df.size for df in features_array]\n",
    "k = int(np.median(lengths))\n",
    "# Example of handling non-numeric data before flattening\n",
    "processed_features = []\n",
    "encoder = OneHotEncoder(sparse=False)  # Initialize one-hot encoder\n",
    "\n",
    "for df in features_array:\n",
    "    # Check and transform non-numeric columns if necessary\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:\n",
    "            # Assuming the non-numeric data is categorical and not text like 'Times New Roman'\n",
    "            transformed = encoder.fit_transform(df[[col]])\n",
    "            df = pd.concat([df.drop(col, axis=1), pd.DataFrame(transformed)], axis=1)\n",
    "    \n",
    "    # Flatten and standardize lengths as before\n",
    "    flattened = df.values.flatten()\n",
    "    # Use a fixed length 'k' determined as before\n",
    "    if len(flattened) > k:\n",
    "        processed_features.append(flattened[:k])\n",
    "    else:\n",
    "        processed_features.append(np.pad(flattened, (0, k - len(flattened)), 'constant'))\n",
    "\n",
    "X = np.array(processed_features)\n",
    "y = labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in X: True\n",
      "Infs in X: False\n",
      "NaNs in X after replacement: False\n",
      "Infs in X after replacement: False\n"
     ]
    }
   ],
   "source": [
    "print(\"NaNs in X:\", np.isnan(X).any())\n",
    "print(\"Infs in X:\", np.isinf(X).any())\n",
    "\n",
    "# If there are any, you might want to consider replacing them\n",
    "if np.isnan(X).any() or np.isinf(X).any():\n",
    "    # Replace NaNs with the mean of the column\n",
    "    col_mean = np.nanmean(X, axis=0)  # Mean ignoring NaNs\n",
    "    # Find indices where NaN values are\n",
    "    inds = np.where(np.isnan(X))\n",
    "    # Replace NaNs with the mean of each column\n",
    "    X[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "    # Replace infinities with large finite numbers\n",
    "    X[np.isinf(X)] = 1e+18  # You might choose a suitable finite number\n",
    "\n",
    "    # Re-check\n",
    "    print(\"NaNs in X after replacement:\", np.isnan(X).any())\n",
    "    print(\"Infs in X after replacement:\", np.isinf(X).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tobia\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "      immersive - easy       0.67      0.40      0.50         5\n",
      "      immersive - hard       0.50      0.43      0.46         7\n",
      "    immersive - normal       0.57      0.36      0.44        11\n",
      "       skimming - easy       0.52      0.46      0.49        56\n",
      "       skimming - hard       0.64      0.49      0.55        72\n",
      "     skimming - normal       0.55      0.72      0.62        90\n",
      "skimming - really hard       0.50      0.60      0.55         5\n",
      "\n",
      "              accuracy                           0.56       246\n",
      "             macro avg       0.56      0.49      0.52       246\n",
      "          weighted avg       0.57      0.56      0.55       246\n",
      "\n",
      "Fold Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "      immersive - easy       0.33      0.20      0.25         5\n",
      "      immersive - hard       1.00      0.43      0.60         7\n",
      "    immersive - normal       0.25      0.09      0.13        11\n",
      "       skimming - easy       0.44      0.27      0.33        56\n",
      "       skimming - hard       0.64      0.62      0.63        72\n",
      "     skimming - normal       0.53      0.77      0.63        90\n",
      "skimming - really hard       0.50      0.20      0.29         5\n",
      "\n",
      "              accuracy                           0.55       246\n",
      "             macro avg       0.53      0.37      0.41       246\n",
      "          weighted avg       0.54      0.55      0.52       246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tobia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tobia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tobia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "       immersive - easy       0.40      0.40      0.40         5\n",
      "       immersive - hard       0.44      0.57      0.50         7\n",
      "     immersive - normal       0.33      0.09      0.14        11\n",
      "immersive - really hard       0.00      0.00      0.00         1\n",
      "        skimming - easy       0.62      0.51      0.56        55\n",
      "        skimming - hard       0.62      0.50      0.55        72\n",
      "      skimming - normal       0.54      0.73      0.62        90\n",
      " skimming - really hard       1.00      0.60      0.75         5\n",
      "\n",
      "               accuracy                           0.57       246\n",
      "              macro avg       0.49      0.43      0.44       246\n",
      "           weighted avg       0.57      0.57      0.56       246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tobia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tobia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tobia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "       immersive - easy       0.40      0.33      0.36         6\n",
      "       immersive - hard       1.00      0.43      0.60         7\n",
      "     immersive - normal       0.62      0.50      0.56        10\n",
      "immersive - really hard       0.00      0.00      0.00         1\n",
      "        skimming - easy       0.52      0.44      0.48        55\n",
      "        skimming - hard       0.56      0.56      0.56        72\n",
      "      skimming - normal       0.51      0.62      0.56        90\n",
      " skimming - really hard       1.00      0.25      0.40         4\n",
      "\n",
      "               accuracy                           0.53       245\n",
      "              macro avg       0.58      0.39      0.44       245\n",
      "           weighted avg       0.55      0.53      0.53       245\n",
      "\n",
      "Fold Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "      immersive - easy       0.80      0.67      0.73         6\n",
      "      immersive - hard       0.75      0.50      0.60         6\n",
      "    immersive - normal       0.33      0.10      0.15        10\n",
      "       skimming - easy       0.56      0.48      0.52        56\n",
      "       skimming - hard       0.55      0.62      0.58        72\n",
      "     skimming - normal       0.60      0.66      0.62        90\n",
      "skimming - really hard       0.50      0.40      0.44         5\n",
      "\n",
      "              accuracy                           0.58       245\n",
      "             macro avg       0.58      0.49      0.52       245\n",
      "          weighted avg       0.57      0.58      0.57       245\n",
      "\n",
      "Mean Accuracy: 0.5578131740501078\n",
      "Standard Deviation of Accuracy: 0.014606834724180456\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=250,  # Number of trees in the forest\n",
    "                                  random_state=224182,   # Seed for reproducibility\n",
    "                                  n_jobs=-1)         # Use all available cores\n",
    "\n",
    "# Set up stratified cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=224182)\n",
    "\n",
    "accuracies = []\n",
    "confusion_matrices = []\n",
    "\n",
    "# Cross-validation\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Flatten the data\n",
    "    X_train_flattened = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test_flattened = X_test.reshape(X_test.shape[0], -1)\n",
    "    \n",
    "    # Train the model on the flattened data\n",
    "    rf_model.fit(X_train_flattened, y_train)\n",
    "    \n",
    "    # Predict on the test set using the flattened test data\n",
    "    y_pred = rf_model.predict(X_test_flattened)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    # Print classification report for each fold\n",
    "    print(f\"Fold Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "    \n",
    "    # Generate confusion matrix for each fold\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "# Print overall accuracy\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies)}\")\n",
    "print(f\"Standard Deviation of Accuracy: {np.std(accuracies)}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
