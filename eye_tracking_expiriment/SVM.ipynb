{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "# used chatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features and labels\n",
    "features_array = np.load('x_data.npy', allow_pickle=True)\n",
    "labels_array = np.load('y_label.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [\n",
    "   'font_size', 'right_gaze_point_in_user_x', 'left_gaze_point_in_user_z', \n",
    "   'left_gaze_point_on_display_area_y', 'right_gaze_point_on_display_area_x', \n",
    "   'right_gaze_point_in_user_z', 'right_gaze_point_in_user_y', \n",
    "   'left_gaze_point_in_user_x', 'right_pupil_diameter', \n",
    "   'left_gaze_origin_in_trackbox_z', 'right_gaze_origin_in_trackbox_y', \n",
    "   'left_gaze_origin_in_trackbox_x', 'right_gaze_origin_in_user_z', \n",
    "   'left_gaze_origin_in_user_x', 'left_gaze_origin_in_user_y', \n",
    "   'left_gaze_origin_validity', 'right_gaze_origin_validity', \n",
    "   'device_time_stamp', 'left_gaze_point_validity', \n",
    "   'right_gaze_point_validity', 'left_pupil_validity', 'right_pupil_validity'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataframes = []\n",
    "for df in features_array:\n",
    "    #Drop the columns if they exist, ignore errors if some columns don't exist\n",
    "    new_df = df.drop(columns=columns_to_remove, errors='ignore')\n",
    "    processed_dataframes.append(new_df)\n",
    "\n",
    "features_array = np.array(processed_dataframes, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "lengths = [df.size for df in features_array]\n",
    "k = int(np.median(lengths))\n",
    "# Example of handling non-numeric data before flattening\n",
    "processed_features = []\n",
    "encoder = OneHotEncoder(sparse=False)  # Initialize one-hot encoder\n",
    "\n",
    "for df in features_array:\n",
    "    # Check and transform non-numeric columns if necessary\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:\n",
    "            # Assuming the non-numeric data is categorical and not text like 'Times New Roman'\n",
    "            transformed = encoder.fit_transform(df[[col]])\n",
    "            df = pd.concat([df.drop(col, axis=1), pd.DataFrame(transformed)], axis=1)\n",
    "    \n",
    "    # Flatten and standardize lengths as before\n",
    "    flattened = df.values.flatten()\n",
    "    # Use a fixed length 'k' determined as before\n",
    "    if len(flattened) > k:\n",
    "        processed_features.append(flattened[:k])\n",
    "    else:\n",
    "        processed_features.append(np.pad(flattened, (0, k - len(flattened)), 'constant'))\n",
    "\n",
    "X = np.array(processed_features)\n",
    "y = labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in X: True\n",
      "Infs in X: False\n",
      "NaNs in X after replacement: False\n",
      "Infs in X after replacement: False\n"
     ]
    }
   ],
   "source": [
    "print(\"NaNs in X:\", np.isnan(X).any())\n",
    "print(\"Infs in X:\", np.isinf(X).any())\n",
    "\n",
    "# If there are any, you might want to consider replacing them\n",
    "if np.isnan(X).any() or np.isinf(X).any():\n",
    "    # Replace NaNs with the mean of the column\n",
    "    col_mean = np.nanmean(X, axis=0)  # Mean ignoring NaNs\n",
    "    # Find indices where NaN values are\n",
    "    inds = np.where(np.isnan(X))\n",
    "    # Replace NaNs with the mean of each column\n",
    "    X[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "    # Replace infinities with large finite numbers\n",
    "    X[np.isinf(X)] = 1e+18  # You might choose a suitable finite number\n",
    "\n",
    "    # Re-check\n",
    "    print(\"NaNs in X after replacement:\", np.isnan(X).any())\n",
    "    print(\"Infs in X after replacement:\", np.isinf(X).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=224182)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='poly')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the SVM classifier\n",
    "svm_model = SVC(kernel='poly')  # You can choose other kernels like 'rbf'\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4349593495934959\n",
      "Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "      immersive - easy       0.00      0.00      0.00         6\n",
      "      immersive - hard       0.00      0.00      0.00         4\n",
      "    immersive - normal       0.67      0.33      0.44        12\n",
      "       skimming - easy       0.00      0.00      0.00        51\n",
      "       skimming - hard       0.00      0.00      0.00        66\n",
      "     skimming - normal       0.43      0.99      0.60       104\n",
      "skimming - really hard       0.00      0.00      0.00         3\n",
      "\n",
      "              accuracy                           0.43       246\n",
      "             macro avg       0.16      0.19      0.15       246\n",
      "          weighted avg       0.22      0.43      0.28       246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tobia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tobia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tobia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'immersive - normal': 53,\n",
       "         'immersive - easy': 27,\n",
       "         'immersive - hard': 34,\n",
       "         'skimming - normal': 450,\n",
       "         'skimming - easy': 278,\n",
       "         'skimming - hard': 360,\n",
       "         'immersive - really hard': 2,\n",
       "         'skimming - really hard': 24})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count the occurrences of each label\n",
    "label_counts = Counter(labels_array)\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36644951140065146"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "450/len(labels_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
