{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features and labels\n",
    "features_array = np.load('x_data.npy', allow_pickle=True)\n",
    "labels_array = np.load('y_label.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "lengths = [df.size for df in features_array]\n",
    "k = int(np.median(lengths))\n",
    "# Example of handling non-numeric data before flattening\n",
    "processed_features = []\n",
    "encoder = OneHotEncoder(sparse=False)  # Initialize one-hot encoder\n",
    "\n",
    "for df in features_array:\n",
    "    # Check and transform non-numeric columns if necessary\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:\n",
    "            # Assuming the non-numeric data is categorical and not text like 'Times New Roman'\n",
    "            transformed = encoder.fit_transform(df[[col]])\n",
    "            df = pd.concat([df.drop(col, axis=1), pd.DataFrame(transformed)], axis=1)\n",
    "    \n",
    "    # Flatten and standardize lengths as before\n",
    "    flattened = df.values.flatten()\n",
    "    # Use a fixed length 'k' determined as before\n",
    "    if len(flattened) > k:\n",
    "        processed_features.append(flattened[:k])\n",
    "    else:\n",
    "        processed_features.append(np.pad(flattened, (0, k - len(flattened)), 'constant'))\n",
    "\n",
    "X = np.array(processed_features)\n",
    "y = labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in X: True\n",
      "Infs in X: False\n",
      "NaNs in X after replacement: False\n",
      "Infs in X after replacement: False\n"
     ]
    }
   ],
   "source": [
    "print(\"NaNs in X:\", np.isnan(X).any())\n",
    "print(\"Infs in X:\", np.isinf(X).any())\n",
    "\n",
    "# If there are any, you might want to consider replacing them\n",
    "if np.isnan(X).any() or np.isinf(X).any():\n",
    "    # Replace NaNs with the mean of the column\n",
    "    col_mean = np.nanmean(X, axis=0)  # Mean ignoring NaNs\n",
    "    # Find indices where NaN values are\n",
    "    inds = np.where(np.isnan(X))\n",
    "    # Replace NaNs with the mean of each column\n",
    "    X[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "    # Replace infinities with large finite numbers\n",
    "    X[np.isinf(X)] = 1e+18  # You might choose a suitable finite number\n",
    "\n",
    "    # Re-check\n",
    "    print(\"NaNs in X after replacement:\", np.isnan(X).any())\n",
    "    print(\"Infs in X after replacement:\", np.isinf(X).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='sigmoid')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the SVM classifier\n",
    "svm_model = SVC(kernel='sigmoid')  # You can choose other kernels like 'rbf'\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9308943089430894\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   immersive       1.00      0.11      0.19        19\n",
      "    skimming       0.93      1.00      0.96       227\n",
      "\n",
      "    accuracy                           0.93       246\n",
      "   macro avg       0.97      0.55      0.58       246\n",
      "weighted avg       0.94      0.93      0.90       246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
